{
    "contents" : "# Data collection and flat file saving for all graphics\nlibrary(\"RPToolsDB\")\nlibrary(\"abind\")\nlibrary(\"RPPlotUtils\")\nlibrary(\"boot\")\n\nuser = 'sduprey'\n# JIRA Code (e.g. NAR-#)\nJIRACode = 'NAR-326'\nrepoPath = RP_GetSharedPath(user)\n# Input Data Path\ninputDataPath  = paste(repoPath,'InputData/', user,'/',JIRACode,'/',sep=\"\")\n\n# Output Data Path\noutputDataPath = paste(repoPath,'OutputData/', user,'/',JIRACode,'/',sep=\"\")\n\nsource(\"./RCode/RP_Utilities.R\")\nsource(\"./RCode/RP_BigData_EventStudy_Utilities.R\")\n\n\n# \n# ##### Cusip mapping\n# startDate <- \"2015-01-01\"\n# endDate <- \"2015-02-01\"\n# \n# r1000_request <- paste0(\"select * FROM algoseek.algoseek_r1000 where date_est >= '\",startDate,\"' and date_est >= '\",endDate,\"'\")\n# \n# r1000_minute_data_RPData <- dbGetQuery(dbCon, r1000_request)\n# \n# saveRDS(r1000_minute_data_RPData, file=paste(inputDataPath, \"r1000_minute_data_RPData.rds\"))\nedition = \"FULL\"\n\n# We are interested in US, UK, and EU - Again, order is important\nregion = \"US\"\n\nnb_range <- 180\nnb_minutes_bucket <- 5\n\n# bootstrap_CI <- TRUE\nbootstrap_CI <- FALSE\n\ncomputeCorrado <- TRUE\n\n# 5A5702 Benzinga\n# 9D69F1 MT Newswires\n# 86BD04 FXStreet Economic Calendar\n# CBEE83 FXStreet News\n# ED68DC Alliance News\n# C98333 Ticker Report\n# CAF988 SleekMoney\n\n\naggregation_df <- NULL\ncounter <- 1\nallbetacorrado <- 6\n# allbetacorrado <- 1\n\nprint(\"Running version : close excluded\")\ntotal_processed_minute_event_dfWhole <- readRDS(file = paste0(outputDataPath,\"ALLtmp_66events.rds\"))\n\nprint(\"Total dimension\")\nprint(dim(total_processed_minute_event_dfWhole))\n\ncorradoStatsAll <- NULL\nreturnsStatsAll <- NULL\nvolumeStatsAll <- NULL\nvolatilityStatsAll <- NULL\n\n\n\n\nsentiment_criterias <- c(\"POSITIVE\",\"NEGATIVE\")\n# sentiment_criterias <- c(\"POSITIVE\")\naggregate_criterias <- c(\"CATEGORY\",\"GROUP\")\n\nRELEVANCE <- c(\"LOW\",\"MEDIUM\",\"HIGH\")\nEVENT_RELEVANCE <- c(\"LOW\",\"MEDIUM\",\"HIGH\")\nRELEVANCE_EVENT_RELEVANCE_COMBO <- c(\"HIGH_HIGH\",\"HIGH_MEDIUM\",\"HIGH_LOW\",\"MEDIUM_MEDIUM\",\"MEDIUM_LOW\",\"LOW_LOW\")\n\n\nSOURCE_CRITERIA <-  c(\"DJ\",\"PREMIUM\",\"ALLBUTPREMIUM\")\n\nEVENT_SIMILARITY_DAYS <-  c(0,1,7,30,90,186,365)\n\n# total_processed_minute_event_dfWhole$YEAR <- year(total_processed_minute_event_dfWhole$DATE)\n# max_year <- max(total_processed_minute_event_dfWhole$YEAR)\n# min_year <- min(total_processed_minute_event_dfWhole$YEAR)\n\nfor (my_source in SOURCE_CRITERIA){\n  for (my_event_relevance_combo in RELEVANCE_EVENT_RELEVANCE_COMBO){\n    for (similarity_gap_filter in EVENT_SIMILARITY_DAYS){\n      for (aggregate_criteria in aggregate_criterias){\n        for (sentiment_criteria in sentiment_criterias){\n          \n          # total_processed_minute_event_df <- readRDS(file = paste0(outputDataPath,\"R1000From2007_total_processed_minute_event_beta_market_df.rds\"))\n          total_processed_minute_event_df <- total_processed_minute_event_dfWhole\n          total_dim <- dim(total_processed_minute_event_df)[1]\n          print(total_dim)\n          \n          ####################          \n          ####################          \n          #################### no time lapse nor GICS sector for the momment          \n          #           if(lapse != -1){\n          #             total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$YEAR >= (max_year - lapse),]\n          #           }\n          #           if(gics_sector != -1){\n          #             total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$INDUSTRY_LEVEL_1 == gics_sector,]\n          #           }\n          \n          total_processed_minute_event_df <- total_processed_minute_event_df[(total_processed_minute_event_df$SOURCE == my_source),]\n          \n          if (aggregate_criteria == \"CATEGORY\"){\n            total_processed_minute_event_df$EVENT <- total_processed_minute_event_df$CATEGORY\n            # total_processed_volume_minute_event_df$EVENT <- total_processed_volume_minute_event_df$CATEGORY      \n          }\n          \n          if (aggregate_criteria == \"GROUP\"){\n            total_processed_minute_event_df$EVENT <- total_processed_minute_event_df$GROUP\n            # total_processed_volume_minute_event_df$EVENT <- total_processed_volume_minute_event_df$GROUP\n          }\n          \n          if(my_event_relevance_combo == \"HIGH_HIGH\"){\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$RELEVANCE >= 100,]\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_RELEVANCE >= 90,]\n            my_relevance <- \"HIGH\"\n            my_event_relevance <- \"HIGH\"\n          }\n          if(my_event_relevance_combo == \"HIGH_MEDIUM\"){\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$RELEVANCE >= 100,]\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_RELEVANCE >= 70 & total_processed_minute_event_df$EVENT_RELEVANCE <= 90,]\n            my_relevance <- \"HIGH\"\n            my_event_relevance <- \"MEDIUM\"\n          }\n          if(my_event_relevance_combo == \"HIGH_LOW\"){\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$RELEVANCE >= 100,]\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_RELEVANCE <= 70,]\n            my_relevance <- \"HIGH\"\n            my_event_relevance <- \"LOW\"\n          }\n          if(my_event_relevance_combo == \"MEDIUM_MEDIUM\"){\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$RELEVANCE >= 90 & total_processed_minute_event_df$RELEVANCE <100,]\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_RELEVANCE >= 70 & total_processed_minute_event_df$EVENT_RELEVANCE <= 90,]\n            my_relevance <- \"MEDIUM\"\n            my_event_relevance <- \"MEDIUM\"\n          }\n          if(my_event_relevance_combo == \"MEDIUM_LOW\"){\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$RELEVANCE >= 90 & total_processed_minute_event_df$RELEVANCE <100,]\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_RELEVANCE <= 70,]\n            my_relevance <- \"MEDIUM\"\n            my_event_relevance <- \"LOW\"\n          }\n          if(my_event_relevance_combo == \"LOW_LOW\"){\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$RELEVANCE <= 90,]\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_RELEVANCE <= 70,]\n            my_relevance <- \"LOW\"\n            my_event_relevance <- \"LOW\"\n          }\n          \n\n          \n          total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_SIMILARITY_DAYS >= similarity_gap_filter,]\n          # total_processed_volume_minute_event_df <- total_processed_volume_minute_event_df[total_processed_volume_minute_event_df$SIMILARITY_GAP >= similarity_gap_filter,]\n          \n          if (sentiment_criteria == \"POSITIVE\"){\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_SENTIMENT_SCORE > 0,]\n            # total_processed_volume_minute_event_df <- total_processed_volume_minute_event_df[total_processed_volume_minute_event_df$ESS>50,]\n            \n          }\n          \n          if (sentiment_criteria == \"NEGATIVE\"){\n            total_processed_minute_event_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT_SENTIMENT_SCORE < 0,]\n            # total_processed_volume_minute_event_df <- total_processed_volume_minute_event_df[total_processed_volume_minute_event_df$ESS<50,]\n          }\n          \n          print(\"Total dimension of all events for the study after various parameters filtering\")\n          print(\"Dimension reduction\")\n          print(dim(total_processed_minute_event_df)[1]/total_dim)\n          print(\"Dimension\")\n          print(dim(total_processed_minute_event_df)[1])\n          # print(dim(total_processed_volume_minute_event_df))\n          \n          \n          for(my_event in unique(total_processed_minute_event_df$EVENT)){\n            filtered_df <- total_processed_minute_event_df[total_processed_minute_event_df$EVENT == my_event,]\n            event_number_event_filtering <- dim(filtered_df)[1]\n            \n            \n            volatilityStats <- outputVolatility(my_relevance, my_event_relevance, aggregate_criteria,sentiment_criteria,similarity_gap_filter,event_number_event_filtering,my_event, localSource = my_source, dataFrame = filtered_df, Russell_version = \"R1000\")\n            \n            \n            volatilityStatsAll <- rbind(volatilityStatsAll,volatilityStats)\n            \n            \n            volumeStats <- outputVolumes(my_relevance, my_event_relevance, aggregate_criteria,sentiment_criteria,similarity_gap_filter,event_number_event_filtering,my_event, localSource = my_source, dataFrame = filtered_df, Russell_version = \"R1000\")\n            volumeStatsAll <- rbind(volumeStatsAll,volumeStats)\n            \n            \n            returnStats <- outputGraphics(my_relevance, my_event_relevance, aggregate_criteria,sentiment_criteria,similarity_gap_filter,event_number_event_filtering,my_event, localSource = my_source, dataFrame = filtered_df, Russell_version = \"R1000\")\n            returnsStatsAll <- rbind(returnsStatsAll,returnStats)\n            \n            \n            corradoCenteredStats <- outputCorradoStatistics(my_relevance, my_event_relevance, aggregate_criteria,sentiment_criteria,similarity_gap_filter,event_number_event_filtering,my_event, localSource = my_source, dataFrame = filtered_df, Russell_version = \"R1000\")\n            ordinCenteredStats <- outputORDINStatistics(my_relevance, my_event_relevance, aggregate_criteria,sentiment_criteria,similarity_gap_filter,event_number_event_filtering,my_event, localSource = my_source, dataFrame = filtered_df, Russell_version = \"R1000\")\n            \n            toplotdf <- merge(ordinCenteredStats$toplot_event_minutes_matrix_all_methodo,corradoCenteredStats$toplot_event_minutes_matrix_all_methodo,by=\"MINUTES\")\n            \n            # outputGraphicsTogether(product_criteria,aggregate_criteria,sentiment_criteria,similarity_gap_filter,ens_filter,event_number_event_filtering, gics_sector,my_event, localSource = NULL, dataFrame = toplotdf,plotInArborescence = FALSE,Russell_version = \"R1000\")\n            \n            retToAdd <- returnStats[,1:73]\n            colnames(retToAdd) <- paste0(\"RET\",colnames(retToAdd))\n            \n            \n            ordToAdd <- ordinCenteredStats$event_minutes_matrix_all_methodo[,1:73]\n            colnames(ordToAdd) <- paste0(\"ORD\",colnames(ordToAdd))\n            \n            voluToAdd <- volumeStats[,1:73]\n            colnames(voluToAdd) <- paste0(\"VOLU\",colnames(voluToAdd))\n            \n            \n            volaToAdd <- volatilityStats[,1:73]\n            colnames(volaToAdd) <- paste0(\"VOLA\",colnames(volaToAdd))\n            \n            corradoCenteredStats$event_minutes_matrix_all_methodo <- cbind(corradoCenteredStats$event_minutes_matrix_all_methodo,retToAdd,ordToAdd,voluToAdd,volaToAdd)\n            # ordinCenteredStats$event_minutes_matrix_all_methodo <- cbind(ordinCenteredStats$event_minutes_matrix_all_methodo,retToAdd,corrToAdd)\n            corradoStatsAll <- rbind(corradoStatsAll,corradoCenteredStats$event_minutes_matrix_all_methodo)\n            # corradoStatsAll <- rbind(corradoStatsAll,ordinCenteredStats$event_minutes_matrix_all_methodo)\n            \n            print(\"Results size increasing to\")\n            print(dim(corradoStatsAll))\n          }\n        }\n      }\n    }\n  }\n}\n\n\nRP_SaveDataFrame(dataframe = corradoStatsAll, outputDataPath = outputDataPath,filename = paste0(bootstrap_CI,\"r1000_bigdata_abvol_abvol_corrado_df\"))\n\n",
    "created" : 1475234043639.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4075938867",
    "id" : "B0C84651",
    "lastKnownWriteTime" : 1475243792,
    "path" : "E:/research/Projects/sduprey/NAR-326/RCode/BIG_DATA/NAR-326_minute_data_equity_data_graph_outputing_beta_all_together_plus_volume_plus_volatility.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_source"
}